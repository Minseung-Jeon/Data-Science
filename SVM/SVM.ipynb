{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373f1644",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b308030",
   "metadata": {},
   "source": [
    "# Question 1 - reference the image file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5b64a",
   "metadata": {},
   "source": [
    "## Question 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e238b40",
   "metadata": {},
   "source": [
    "In SVM what is the meaning of margin? Which are the equations of the two margin hyperplans H+ and H- ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e7e34",
   "metadata": {},
   "source": [
    "In SVM, the margin is the distance between the hyperplane and the data points from either class. The equation for the H+ margin is $w^Tx + b = 1$ and the equation for the H- margin is $w^Tx + b = -1$ where $w$ is the weight vector, $x$ is the input vector and $b$ is the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca85a7",
   "metadata": {},
   "source": [
    "## Question 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1e0bc",
   "metadata": {},
   "source": [
    "Consider the three linearly separable two-dimensional input vectors in the following figure. Find the linear SVM that optimally separates the classes by maximizing the margin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4a645",
   "metadata": {},
   "source": [
    "We can first define the hyperplane function as $h(X) = W^TX + b = w{_1}x{_1} + w{_2}x{_2} + b = 0$.\n",
    "We can then rearrange it as: $x{_2} = -\\frac{w{_1}}{w{_2}}x{_1} - \\frac{b}{w{_2}}$. From this equation we can get the slope using the points $x{_1}$ = (2,0) and $x{_2}$ = (0,2) : $\\frac{w{_1}}{w{_2}} = \\frac{2-0}{0-2} = -\\frac{1}{1}$. We can then find the offset: $b = -(-1)x{_1}-1x{_2} = 2$. Therefore, the hyperplane is $h(X) = W^TX + b = -X + 2 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd465cf3",
   "metadata": {},
   "source": [
    "## Question 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66693d70",
   "metadata": {},
   "source": [
    "What is a kernel function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c2fc3",
   "metadata": {},
   "source": [
    "A kernel function is used to take our dataset and map it to a higher feature space. For example the linear kernel function is $K(x,x{_i}) + c$ which is the most simple kernel function. The kernel function usually requires the calculation of the inner dot product but with polynomial functions, we can use the degree as an exponent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de6842",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6d9517",
   "metadata": {},
   "source": [
    "Compare Neural Network and SVM in Classification of heart disease data set in Python language. You can use the sklearn Python library to implement both Neural Networks and SVM. For SVM, build the model by changing the different kernels such as Linear, Gaussian and Sigmoid and note down the model accuracy. Similarly, use Stochastic Gradient Descent and Adam Gradient Descent to build the multi-layer Neural Network and note down the model accuracy for each. Finally, tell us which model performs better and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4040ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 0.6333333333333333\n",
      "Gaussian SVM Accuracy: 0.65\n",
      "Sigmoid SVM Accuracy: 0.6\n",
      "Stochastic Gradient Descent Neural Networks Accuracy: 0.6\n",
      "Adam Gradient Descent Neural Networks Accuracy: 0.6166666666666667\n",
      "The SVM models in both cases work better than the Neural Networks models\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load dataset\n",
    "data = pd.read_csv(\"heart-disease-dataset.csv\", na_values='?').dropna()\n",
    "X = data.drop('result', axis = 1)\n",
    "Y = data['result']\n",
    "\n",
    "# split the data into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# linear SVM\n",
    "linear_svm = SVC(kernel = 'linear')\n",
    "linear_svm.fit(X_train_scaled, Y_train)\n",
    "linear_svm_pred = linear_svm.predict(X_test_scaled)\n",
    "linear_svm_accuracy = accuracy_score(Y_test, linear_svm_pred)\n",
    "print('Linear SVM Accuracy:',linear_svm_accuracy)\n",
    "\n",
    "# gaussian SVM\n",
    "gaussian_svm = SVC(kernel = 'rbf')\n",
    "gaussian_svm.fit(X_train_scaled, Y_train)\n",
    "gaussian_svm_pred = gaussian_svm.predict(X_test_scaled)\n",
    "gaussian_svm_accuracy = accuracy_score(Y_test, gaussian_svm_pred)\n",
    "print('Gaussian SVM Accuracy:', gaussian_svm_accuracy)\n",
    "\n",
    "# sigmoid SVM\n",
    "sigmoid_svm = SVC(kernel = 'sigmoid')\n",
    "sigmoid_svm.fit(X_train_scaled, Y_train)\n",
    "sigmoid_svm_pred = sigmoid_svm.predict(X_test_scaled)\n",
    "sigmoid_svm_accuracy = accuracy_score(Y_test, sigmoid_svm_pred)\n",
    "print('Sigmoid SVM Accuracy:',sigmoid_svm_accuracy)\n",
    "\n",
    "# stochastic gradient descent neural network\n",
    "sgd_nn = MLPClassifier(solver = 'sgd', max_iter = 1000, random_state=42)\n",
    "sgd_nn.fit(X_train_scaled, Y_train)\n",
    "sgd_nn_pred = sgd_nn.predict(X_test_scaled)\n",
    "sgd_nn_accuracy = accuracy_score(Y_test, sgd_nn_pred)\n",
    "print('Stochastic Gradient Descent Neural Networks Accuracy:',sgd_nn_accuracy)\n",
    "\n",
    "# adam gradient descent neural network\n",
    "agd_nn = MLPClassifier(solver = 'adam', max_iter = 1000, random_state=42)\n",
    "agd_nn.fit(X_train_scaled, Y_train)\n",
    "agd_nn_pred = agd_nn.predict(X_test_scaled)\n",
    "agd_nn_accuracy = accuracy_score(Y_test, agd_nn_pred)\n",
    "print('Adam Gradient Descent Neural Networks Accuracy:',agd_nn_accuracy)\n",
    "\n",
    "print('The SVM models in both cases work better than the Neural Networks models')\n",
    "                                                    \n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa55b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
